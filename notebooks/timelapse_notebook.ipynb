{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timelapse notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timelapse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '../source/python')\n",
    "output_dir = '../output/'\n",
    "os.makedirs(output_dir,exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.width', 100)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_roma_standardized = '../data/temp_data/ro_standard.xlsx'\n",
    "file_roma_IDA = '../data/roma_blind_prediction/ID segmentali con IDA Score.xlsx'\n",
    "file_roma_blind = '../data/roma_blind_prediction/inviato a matteo_v3.xlsx'\n",
    "file_roma_blind_correction = '../data/roma_blind_prediction/segmentali_per_silvia_SC_MF.xlsx'\n",
    "file_valencia_standardized = '../data/temp_data/va_standard.xlsx'\n",
    "file_uk_standardized = '../data/temp_data/uk_standard.xlsx'\n",
    "file_bologna = '../data/input_data/9.baby TLM Mophokinetics Parameters.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definire i parametri utilizzati\n",
    "selected_feature_list = ['tPNa_imp','t3_imp','t5_imp','t6_imp','t7_imp','t8_imp','t9_imp','cc3_imp', 's3_imp','blast_imp']\n",
    "raw_feature_list = ['tPNa', 'tPNf', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 'tM', 'tSB', 'tB', 'tEB']\n",
    "# parametri per dataset Genera aggiuntivi\n",
    "grading_dict = {'AA':'AA','AB':'AB,BA','BA':'AB,BA','AC':'AC,CA,BB','CA':'AC,CA,BB','BB':'AC,CA,BB','CB':'CC,BC,CB','BC':'CC,BC,CB','CC':'CC,BC,CB','-':'-'}\n",
    "grading_dict_num = {'AA':0,'AB,BA':1,'AC,CA,BB':2,'CC,BC,CB':3,'-':4}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and clean roma\n",
    "# dataset roma contiene anche i dati aggiuntivi di IDA score\n",
    "df_roma = pd.read_excel(file_roma_standardized)\n",
    "df_roma['Sample ID'] = df_roma['patient_ID'].astype(str)+'_'+df_roma['embryo_ID'].astype(str)+'.'+df_roma['treatment_ID'].astype(str)\n",
    "df_roma['class'] = df_roma['classification'].map({'eup':'eup','ane':'aneup','seg':'segm','ane_seg':'segm+aneup'})\n",
    "df_roma = df_roma.replace('-',np.nan)\n",
    "df_ida = pd.read_excel(file_roma_IDA)#,sheet_name='Cleavage features')\n",
    "df_ida['ida score'] = df_ida['ida score'].replace('missing',None).astype(float)\n",
    "df_ida.rename(columns={'operator\\'s grading':'operators\\' grading','ida score':'IDA Score'},inplace=True)\n",
    "df_ida['grading_grouped'] = df_ida['operators\\' grading'].map(grading_dict)\n",
    "df_ida['grading_grouped_num'] = df_ida['grading_grouped'].map(grading_dict_num).fillna(4)\n",
    "df_roma = pd.merge(df_roma,df_ida,on=['Sample ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roma.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and clean unblind\n",
    "df_unblind = pd.read_excel(file_roma_blind,sheet_name='unblinded')\n",
    "df_unblind['IDA Score'] = df_unblind['IDA Score'].replace('-',None).astype(float)\n",
    "df_unblind['grading_grouped'] = df_unblind['operators\\' grading'].map(grading_dict)\n",
    "df_unblind['grading_grouped_num'] = df_unblind['grading_grouped'].map(grading_dict_num).fillna(4)\n",
    "df_unblind['class'] = df_unblind['eup, aneup, segm, segm+aneup'].map({0:'eup',1:'aneup',2:'segm',3:'segm+aneup'})\n",
    "df_unblind = df_unblind.replace('-',np.nan)\n",
    "df_unblind = df_unblind.rename(columns={'t9+':'t9'})\n",
    "df_unblind_correction = pd.read_excel(file_roma_blind_correction)\n",
    "for i,j in df_unblind_correction.iterrows():\n",
    "    embryoID = j['ID_Emb']\n",
    "    corrected_class = j['CheckClass eup ane seg aneseg']\n",
    "    df_unblind.loc[df_unblind['ID_Emb']==embryoID,'class'] = corrected_class\n",
    "df_unblind = df_unblind[df_unblind['class']!='?'].reset_index()\n",
    "df_unblind['centre_ID'] = 'roma_unblind'\n",
    "df_unblind['patient_ID'] = df_unblind['ID_Emb'].str.split('_').apply(lambda x: x[0])\n",
    "df_unblind['treatment_ID'] = df_unblind['ID_Ciclo']\n",
    "df_unblind['embryo_ID'] = df_unblind['ID_Emb']\n",
    "\n",
    "#load and clean blind\n",
    "df_blind = pd.read_excel(file_roma_blind,sheet_name='blinded')\n",
    "df_blind['IDA Score'] = df_blind['IDA Score'].replace('-',None).astype(float)\n",
    "df_blind['grading_grouped'] = df_blind['operators\\' grading'].map(grading_dict)\n",
    "df_blind['grading_grouped_num'] = df_blind['grading_grouped'].map(grading_dict_num).fillna(4)\n",
    "df_blind = df_blind.replace('-',np.nan)\n",
    "df_blind = df_blind.rename(columns={'t9+':'t9'})\n",
    "df_blind['centre_ID'] = 'roma_blind'\n",
    "df_blind['patient_ID'] = df_blind['ID_Emb'].str.split('_').apply(lambda x: x[0])\n",
    "df_blind['treatment_ID'] = df_blind['ID_Ciclo']\n",
    "df_blind['embryo_ID'] = df_blind['ID_Emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unblind.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blind.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and clean valencia\n",
    "df_valencia = pd.read_excel(file_valencia_standardized)\n",
    "df_valencia['class'] = df_valencia['classification'].map({'eup':'eup','ane':'aneup','seg':'segm','ane_seg':'segm+aneup'})\n",
    "df_valencia = df_valencia.replace('-',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valencia.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and clean UK\n",
    "df_uk = pd.read_excel(file_uk_standardized)\n",
    "df_uk['class'] = df_uk['classification'].map({'eup':'eup','ane':'aneup','seg':'segm','ane_seg':'segm+aneup'})\n",
    "df_uk = df_uk.replace('-',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uk.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load bologna\n",
    "df_bologna = pd.read_excel(file_bologna)\n",
    "df_bologna['centre_ID']='bologna'\n",
    "df_bologna['treatment_ID'] = df_bologna['Sample ID'].str.split('_').apply(lambda x: x[0])\n",
    "df_bologna['patient_ID'] = df_bologna['Sample ID'].str.split('_').apply(lambda x: x[0])\n",
    "df_bologna['class'] = 'eup'\n",
    "df_bologna.loc[df_bologna['Molecular Karyotype'].apply(lambda x: 'ANEUPLOIDE' in x),'class']='aneup'\n",
    "df_bologna.loc[df_bologna['Molecular Karyotype'].apply(lambda x: 'aneup' in x),'class']='aneup'\n",
    "df_bologna.loc[df_bologna['Molecular Karyotype'].apply(lambda x: 'SEGMENTAL' in x),'class']='segm'\n",
    "df_bologna.loc[df_bologna['Molecular Karyotype'].apply(lambda x: ',' in x),'class']='segm+aneup'\n",
    "df_bologna.loc[df_bologna['Molecular Karyotype'].apply(lambda x: ('+' in x)&('-' in x)),'class']='segm+aneup'\n",
    "\n",
    "df_bologna[['Molecular Karyotype','class']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bologna.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contiene anche bologna fare attenzione\n",
    "df_all = pd.concat([df_roma, df_valencia, df_uk, df_unblind,df_bologna])\n",
    "\n",
    "display(df_all.shape) # dimensione dataset merged\n",
    "display(df_all.centre_ID.value_counts()) # dimensioni centro specifico\n",
    "display(df_all['class'].value_counts()) # conte delle classi su dataset merged\n",
    "display(pd.crosstab(df_all.centre_ID, df_all['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['centre_ID','patient_ID','treatment_ID']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_all['class'].value_counts(normalize=True))\n",
    "display(pd.crosstab(df_all.centre_ID,df_all['class'],normalize='index'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[[t + '_missing' for t in raw_feature_list]] = df_all[raw_feature_list].isna()\n",
    "df_all['num_missing'] = df_all[[t + '_missing' for t in raw_feature_list]].sum(axis=1)\n",
    "df_all = df_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(5)\n",
    "#df_all['num_missing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_all,x='num_missing',hue='centre_ID',stat='count',common_norm=False,multiple='stack',hue_order=['IVIRMA','GeneraLife','Care-Fertility'],bins=range(15),shrink=1)\n",
    "plt.axvline(5,c='r',ls='--')\n",
    "plt.xlabel('Number of missing time features')\n",
    "plt.grid()\n",
    "plt.ylabel('Number of embryos')\n",
    "plt.title('prova')\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig(os.path.join(output_dir,'Missing_stat_num.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_feature_list = ['tPNa', 'tPNf', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 'tM', 'tSB', 'tB', 'tEB']\n",
    "df_missing = df_all.groupby('centre_ID')[[t + '_missing' for t in raw_feature_list]].mean().reset_index()\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_melt = df_missing.melt(id_vars='centre_ID')\n",
    "\n",
    "sns.barplot(data=df_missing_melt,y='value',x='variable',hue='centre_ID',hue_order=['IVIRMA','GeneraLife','Care-Fertility'])\n",
    "plt.xticks(range(len(raw_feature_list)),raw_feature_list,rotation=90)\n",
    "#plt.grid()\n",
    "plt.ylabel('Fraction of missing records')\n",
    "plt.grid()\n",
    "plt.title('prova')\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(output_dir,'Missing_stat.jpeg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_melt = df_all[['class']+raw_feature_list].melt(id_vars='class')\n",
    "\n",
    "sns.boxplot(data=df_all_melt,y='value',x='variable',hue='class',hue_order=['eup','aneup','segm','segm+aneup'])\n",
    "plt.xticks(range(len(raw_feature_list)),raw_feature_list,rotation=90)\n",
    "plt.grid()\n",
    "plt.ylabel('Elapsed time (h)')\n",
    "plt.title('Multi-centers')\n",
    "plt.title('prova')\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(output_dir,'boxplot_class.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for myclass in df_all['class'].unique():\n",
    "    df_all_melt = df_all.loc[df_all['class']==myclass,['centre_ID']+raw_feature_list].melt(id_vars='centre_ID')\n",
    "    #print(myclass)\n",
    "    plt.figure()\n",
    "    sns.boxplot(data=df_all_melt,y='value',x='variable',hue='centre_ID',hue_order=['IVIRMA','GeneraLife','Care-Fertility'])\n",
    "    plt.xticks(range(len(raw_feature_list)),raw_feature_list,rotation=90)\n",
    "    plt.grid()\n",
    "    plt.ylabel('Elapsed time (h)')\n",
    "    plt.title(str(myclass))\n",
    "    plt.show()\n",
    "    #plt.savefig(os.path.join(output_dir,myclass+'.jpeg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kolmogorov Smirnov 2 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks2 = pd.DataFrame()\n",
    "dataset_dict = {'GeneraLife':df_roma_processed,'Care-Fertility':df_uk_processed,'IVIRMA':df_valencia_processed,'allcenters':df_all_processed}\n",
    "\n",
    "for center in dataset_dict.keys():\n",
    "    dataset = dataset_dict[center]\n",
    "    for t in tl_all.imputed_times:\n",
    "    #for t in raw_feature_list + ['cc3_imp','cc2_imp','s2_imp','s3_imp','blast1_imp']:\n",
    "        for c1 in ['eup','segm','aneup']:\n",
    "            for c2 in ['eup','segm','aneup']:\n",
    "                if c1 > c2:\n",
    "                    list1 = dataset.loc[dataset['class']==c1, t].dropna()\n",
    "                    list2 = dataset.loc[dataset['class']==c2, t].dropna()\n",
    "                    effect = np.mean(list1) -np.mean(list2)\n",
    "\n",
    "                    statistic, pvalue_ks = stats.ks_2samp(list1, list2)\n",
    "                    statistic, pvalue_tind = stats.ttest_ind(list1,list2)\n",
    "                    # statistic è un valore della statistica poco interpretabile \n",
    "                    # per tale motivo utilizziamo l'effetto medio dei tempi\n",
    "                    df_ks2 = df_ks2.append({'center':center,\n",
    "                                            'c1':c1,'c2':c2,\n",
    "                                            'time':t,\n",
    "                                            'effect':effect,\n",
    "                                            'pvalue_ks':pvalue_ks,\n",
    "                                            'pvalue_tind':pvalue_tind},\n",
    "                                            ignore_index=True)\n",
    "\n",
    "df_ks2['-log10p_ks'] = -np.log10(df_ks2['pvalue_ks'])\n",
    "df_ks2['-log10p_tind'] = -np.log10(df_ks2['pvalue_tind'])\n",
    "# non considerare il p_ttest che riguarda il test T indipendente a due campioni\n",
    "# i nostri dati non sono parametrici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,1,figsize=(16,10))\n",
    "ax[0].set_title('KS 2 samples - Euploids vs Segmentals')\n",
    "sns.barplot(ax=ax[0],data=df_ks2[(df_ks2.c1=='segm')&(df_ks2.c2=='eup')],x='time',y='-log10p_ks',hue='center',hue_order=['allcenters'])\n",
    "ax[1].set_title('KS 2 samples - Euploids vs Aneuploids')\n",
    "sns.barplot(ax=ax[1],data=df_ks2[(df_ks2.c1=='eup')&(df_ks2.c2=='aneup')],x='time',y='-log10p_ks',hue='center',hue_order=['allcenters'])\n",
    "ax[2].set_title('KS 2 samples - Aneuploids vs Segmentals')\n",
    "sns.barplot(ax=ax[2],data=df_ks2[(df_ks2.c1=='segm')&(df_ks2.c2=='aneup')],x='time',y='-log10p_ks',hue='center',hue_order=['allcenters'])\n",
    "\n",
    "\n",
    "ax[0].axhline(2,c='k',ls='--')\n",
    "ax[1].axhline(2,c='k',ls='--')\n",
    "ax[2].axhline(2,c='k',ls='--')\n",
    "ax[0].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[1].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[2].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(output_dir,'significancy_ks.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks2[(df_ks2.c1=='segm')&(df_ks2.c2=='eup')].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,1,figsize=(16,10))\n",
    "ax[0].set_title('KS 2 samples - Segmental vs Euploid')\n",
    "sns.barplot(ax=ax[0],data=df_ks2[(df_ks2.c1=='segm')&(df_ks2.c2=='eup')],x='time',y='-log10p_ks',hue='center')\n",
    "ax[1].set_title('KS 2 samples - Euploid vs Aneuploid')\n",
    "sns.barplot(ax=ax[1],data=df_ks2[(df_ks2.c1=='eup')&(df_ks2.c2=='aneup')],x='time',y='-log10p_ks',hue='center')\n",
    "ax[2].set_title('KS 2 samples - Segmental vs Aneuploid')\n",
    "sns.barplot(ax=ax[2],data=df_ks2[(df_ks2.c1=='segm')&(df_ks2.c2=='aneup')],x='time',y='-log10p_ks',hue='center')\n",
    "\n",
    "\n",
    "ax[0].axhline(2,c='k',ls='--')\n",
    "ax[1].axhline(2,c='k',ls='--')\n",
    "ax[2].axhline(2,c='k',ls='--')\n",
    "ax[0].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[1].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[2].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(output_dir,'significancy_ks_centers.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ks2.c1.unique())\n",
    "display(df_ks2.c2.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sibling analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = pd.merge(df_processed_all, df_processed_all, on=['centre_ID','treatment_ID','patient_ID'],suffixes=['_x','_y'])\n",
    "df_pairs = df_pairs[df_pairs['class_x']>df_pairs['class_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in tl_all.imputed_times:\n",
    "    df_pairs[time + '_delta'] = df_pairs[time + '_y'] - df_pairs[time + '_x']\n",
    "    df_pairs[time + '_binary'] = df_pairs[time + '_y'] - df_pairs[time + '_x'] > 0\n",
    "display(df_pairs.centre_ID.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs.groupby(['centre_ID','class_x','class_y'])[['patient_ID']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs.loc[(df_pairs['class_x']==c1)&(df_pairs['class_y']==c2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sibling = pd.DataFrame()\n",
    "\n",
    "dataset_dict = {'GeneraLife':df_roma_processed,'Care-Fertility':df_uk_processed,'IVIRMA':df_valencia_processed,'allcenters':df_all_processed}\n",
    "\n",
    "for center in dataset_dict.keys():\n",
    "    dataset = dataset_dict[center]\n",
    "    df_pairs = pd.merge(dataset,dataset,on=['centre_ID','treatment_ID','patient_ID'],suffixes=['_x','_y'])\n",
    "    df_pairs = df_pairs[df_pairs['class_x']!=df_pairs['class_y']]\n",
    "    for time in tl_all.imputed_times:\n",
    "        time_delta = time+'_delta'\n",
    "        df_pairs[time_delta] = df_pairs[time+'_y'] - df_pairs[time+'_x']\n",
    "        df_pairs[time+'_binary'] = df_pairs[time+'_y'] - df_pairs[time+'_x'] > 0\n",
    "    \n",
    "        for c1 in ['eup','segm','aneup']:\n",
    "            for c2 in ['eup','segm','aneup']:\n",
    "                if 1==1:#c1 > c2:\n",
    "                    df_sel = df_pairs.loc[(df_pairs['class_x']==c1)&(df_pairs['class_y']==c2)]\n",
    "                    if len(df_sel)>0:\n",
    "\n",
    "                        list1 = df_sel[time_delta].dropna()\n",
    "                        n_success = (list1>0).sum()\n",
    "                        avg_delay = np.mean(list1)\n",
    "                        n_trials = len(list1)\n",
    "                        frac_binary = n_success/n_trials -0.5\n",
    "                        list_zero = np.zeros(n_trials)\n",
    "\n",
    "                        pvalue_bin = stats.binom_test(n_success, n=n_trials, p=0.5, alternative='two-sided')\n",
    "                        statistic, pvalue_wilcoxon = stats.wilcoxon(list1,list_zero)\n",
    "                        \n",
    "\n",
    "\n",
    "                        df_sibling = df_sibling.append({'center':center,'c1':c1,'c2':c2,'time':time,'avg_delay':avg_delay,\n",
    "                                                              'pvalue_bin':pvalue_bin,'pvalue_wilcoxon':pvalue_wilcoxon,'frac_binary':frac_binary},ignore_index=True)\n",
    "\n",
    "\n",
    "df_sibling['-log10p_bin'] = -np.log10(df_sibling['pvalue_bin'])\n",
    "df_sibling['-log10p_wil'] = -np.log10(df_sibling['pvalue_wilcoxon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,1,figsize=(16,10))\n",
    "ax[0].set_title('Binomial test - Segmental vs Euploid')\n",
    "sns.barplot(ax=ax[0],data=df_sibling[(df_sibling.c1=='segm')&(df_sibling.c2=='eup')],x='time',y='-log10p_bin',hue='center',hue_order=['allcenters'])\n",
    "ax[1].set_title('Binomial test - Segmental vs Aneuploid')\n",
    "sns.barplot(ax=ax[1],data=df_sibling[(df_sibling.c1=='segm')&(df_sibling.c2=='aneup')],x='time',y='-log10p_bin',hue='center',hue_order=['allcenters'])\n",
    "ax[2].set_title('Binomial test - Euploid vs Aneuploid')\n",
    "sns.barplot(ax=ax[2],data=df_sibling[(df_sibling.c1=='eup')&(df_sibling.c2=='aneup')],x='time',y='-log10p_bin',hue='center',hue_order=['allcenters'])\n",
    "\n",
    "ax[0].axhline(2,c='k',ls='--')\n",
    "ax[1].axhline(2,c='k',ls='--')\n",
    "ax[2].axhline(2,c='k',ls='--')\n",
    "ax[0].tick_params(axis='x', labelrotation=45)\n",
    "ax[1].tick_params(axis='x', labelrotation=45)\n",
    "ax[2].tick_params(axis='x', labelrotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.title('Binomial test - ')\n",
    "plt.show()\n",
    "# plt.savefig(os.path.join(output_dir,'significancy_sibling_bin.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,1,figsize=(16,10))\n",
    "plt.title('Significancy binomial test')\n",
    "ax[0].set_title('Binomial test - Segmental vs Euploid')\n",
    "sns.barplot(ax=ax[0],data=df_sibling[(df_sibling.c1=='segm')&(df_sibling.c2=='eup')],x='time',y='-log10p_bin',hue='center')\n",
    "ax[1].set_title('Binomial test - Segmental vs Aneuploid')\n",
    "sns.barplot(ax=ax[1],data=df_sibling[(df_sibling.c1=='segm')&(df_sibling.c2=='aneup')],x='time',y='-log10p_bin',hue='center')\n",
    "ax[2].set_title('Binomial test - Euploid vs Aneuploid')\n",
    "sns.barplot(ax=ax[2],data=df_sibling[(df_sibling.c1=='eup')&(df_sibling.c2=='aneup')],x='time',y='-log10p_bin',hue='center')\n",
    "ax[0].axhline(2,c='k',ls='--')\n",
    "ax[1].axhline(2,c='k',ls='--')\n",
    "ax[2].axhline(2,c='k',ls='--')\n",
    "ax[0].tick_params(axis='x', labelrotation=45)\n",
    "ax[1].tick_params(axis='x', labelrotation=45)\n",
    "ax[2].tick_params(axis='x', labelrotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(os.path.join(output_dir,'significancy_siblings_centers_bin.jpeg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wilcoxon signed-rank test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,1,figsize=(16,10))\n",
    "ax[0].set_title('Wilcoxon paired - Euploids vs Segmentals')\n",
    "sns.barplot(ax=ax[0],data=df_sibling[(df_sibling.c1=='segm')&(df_sibling.c2=='eup')],x='time',y='-log10p_wil',hue='center',hue_order=['allcenters'])\n",
    "ax[1].set_title('Wilcoxon paired - Euploid vs Aneuploids')\n",
    "sns.barplot(ax=ax[1],data=df_sibling[(df_sibling.c1=='eup')&(df_sibling.c2=='aneup')],x='time',y='-log10p_wil',hue='center',hue_order=['allcenters'])\n",
    "ax[2].set_title('Wilcoxon paired - Aneuploids vs Segmentals')\n",
    "sns.barplot(ax=ax[2],data=df_sibling[(df_sibling.c1=='segm')&(df_sibling.c2=='aneup')],x='time',y='-log10p_wil',hue='center',hue_order=['allcenters'])\n",
    "\n",
    "ax[0].axhline(2,c='k',ls='--')\n",
    "ax[1].axhline(2,c='k',ls='--')\n",
    "ax[2].axhline(2,c='k',ls='--')\n",
    "ax[0].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[1].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[2].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[0].tick_params(axis='x', labelrotation=45)\n",
    "ax[1].tick_params(axis='x', labelrotation=45)\n",
    "ax[2].tick_params(axis='x', labelrotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.ylim([0,15])\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(output_dir,'significancy_sibling_tind.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,1,figsize=(16,10))\n",
    "ax[0].set_title('Wilcoxon paired - Euploids vs Segmentals')\n",
    "sns.barplot(ax=ax[0],data=df_sibling[(df_sibling.c1=='segm')&(df_sibling.c2=='eup')],x='time',y='-log10p_wil',hue='center')\n",
    "ax[1].set_title('Wilcoxon paired - Euploids vs Aneuploids')\n",
    "sns.barplot(ax=ax[1],data=df_sibling[(df_sibling.c1=='eup')&(df_sibling.c2=='aneup')],x='time',y='-log10p_wil',hue='center')\n",
    "ax[2].set_title('Wilcoxon paired - Aneuploids vs Segmentals')\n",
    "sns.barplot(ax=ax[2],data=df_sibling[(df_sibling.c1=='segm')&(df_sibling.c2=='aneup')],x='time',y='-log10p_wil',hue='center')\n",
    "\n",
    "\n",
    "ax[0].axhline(2,c='k',ls='--')\n",
    "ax[1].axhline(2,c='k',ls='--')\n",
    "ax[2].axhline(2,c='k',ls='--')\n",
    "ax[0].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[1].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[2].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[0].tick_params(axis='x', labelrotation=45)\n",
    "ax[1].tick_params(axis='x', labelrotation=45)\n",
    "ax[2].tick_params(axis='x', labelrotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(output_dir,'significancy_siblings_centers_tind.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,1,figsize=(16,10),sharey=True)\n",
    "ax[0].set_title('Binomial test - Euploids vs Segmentals')\n",
    "sns.barplot(ax=ax[0],data=df_sibling[(df_sibling.c1=='eup')&(df_sibling.c2=='segm')],x='time',y='frac_binary',hue='center')\n",
    "ax[1].set_title('Binomial test - Euploids vs Aneuploids')\n",
    "sns.barplot(ax=ax[1],data=df_sibling[(df_sibling.c1=='eup')&(df_sibling.c2=='aneup')],x='time',y='frac_binary',hue='center')\n",
    "ax[2].set_title('Binomial test - Aneuploids vs Segmentals')\n",
    "sns.barplot(ax=ax[2],data=df_sibling[(df_sibling.c1=='aneup')&(df_sibling.c2=='segm')],x='time',y='frac_binary',hue='center')\n",
    "\n",
    "ax[0].axhline(.0,c='k',ls='-')\n",
    "ax[1].axhline(.0,c='k',ls='-')\n",
    "ax[2].axhline(.0,c='k',ls='-')\n",
    "\n",
    "ax[0].axhline(.1,c='k',ls='--')\n",
    "ax[1].axhline(.1,c='k',ls='--')\n",
    "ax[2].axhline(.1,c='k',ls='--')\n",
    "\n",
    "ax[0].axhline(-0.1,c='k',ls='--')\n",
    "ax[1].axhline(-0.1,c='k',ls='--')\n",
    "ax[2].axhline(-0.1,c='k',ls='--')\n",
    "plt.tight_layout()\n",
    "plt.ylim([-0.25,0.25])\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "ax[2].grid()\n",
    "ax[0].set_yticks([-0.2,-0.1,0,0.1,0.2])\n",
    "ax[0].set_yticklabels([0.3,0.4,0.5,0.6,0.7])\n",
    "ax[1].set_yticks([-0.2,-0.1,0,0.1,0.2])\n",
    "ax[1].set_yticklabels([0.3,0.4,0.5,0.6,0.7])\n",
    "ax[2].set_yticks([-0.2,-0.1,0,0.1,0.2])\n",
    "ax[2].set_yticklabels([0.3,0.4,0.5,0.6,0.7])\n",
    "ax[0].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[1].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[2].legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "ax[0].set_ylabel('segmental sibling\\n is delayed wrt euploid sibling')\n",
    "ax[1].set_ylabel('aneuploid sibling\\n is delayed wrt euploid sibling')\n",
    "ax[2].set_ylabel('segmental sibling\\n is delayed wrt aneuploid sibling')\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(output_dir,'significancy_siblings_centers_frac.jpeg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining training and test sets\n",
    "1. test 40%\n",
    "2. training 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roma_train0, df_roma_test0 = train_test_split(df_roma[df_roma['class'].isin(['segm','eup'])], test_size=0.4,random_state=104)\n",
    "df_roma_train = df_roma_train0.copy()\n",
    "df_roma_test = df_roma_test0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_roma_train.shape)\n",
    "display(df_roma_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_train0, df_val_test0 = train_test_split(df_valencia[df_valencia['class'].isin(['segm','eup'])], test_size=0.4,random_state=104)\n",
    "df_val_train = df_val_train0.copy()\n",
    "df_val_test = df_val_test0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_val_train.shape[0])\n",
    "display(df_val_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uk_train0, df_uk_test0 = train_test_split(df_uk[df_uk['class'].isin(['segm','eup'])], test_size=0.4,random_state=104)\n",
    "df_uk_train = df_uk_train0.copy()\n",
    "df_uk_test = df_uk_test0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_uk_train.shape[0])\n",
    "display(df_uk_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_train = pd.concat([df_roma_train, df_val_train, df_uk_train])\n",
    "df_all_test = pd.concat([df_roma_test, df_val_test, df_uk_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 train 4 models: model specific and global model\n",
    "tl_roma = TimeLapseAnalyzer()\n",
    "tl_roma.train(df_roma_train.copy(), model_feature_list = selected_feature_list + ['ritardo_max','ritardo_min','pca_ll'], target='is_segmental')\n",
    "tl_val = TimeLapseAnalyzer()\n",
    "tl_val.train(df_val_train.copy(), model_feature_list = selected_feature_list + ['ritardo_max','ritardo_min','pca_ll'], target='is_segmental')\n",
    "tl_uk = TimeLapseAnalyzer()\n",
    "tl_uk.train(df_uk_train.copy(), model_feature_list = selected_feature_list + ['ritardo_max','ritardo_min','pca_ll'], target='is_segmental')\n",
    "tl_all = TimeLapseAnalyzer(PCA_LL_TH=-80)\n",
    "tl_all.train(df_all_train.copy(), model_feature_list = selected_feature_list + ['ritardo_max','ritardo_min','pca_ll'], target='is_segmental')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roma_processed = tl_roma.process_data(df_roma, train=False)\n",
    "df_uk_processed = tl_uk.process_data(df_uk, train=False)\n",
    "df_valencia_processed = tl_roma.process_data(df_valencia, train=False)\n",
    "df_all_processed = tl_all.process_data(df_all, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roma_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uk_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valencia_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_processed.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {'roma':tl_roma,'uk':tl_uk,'valencia':tl_val,'allcenters':tl_all}\n",
    "dataset_dict = {'roma':df_roma_test,'uk':df_uk_test,'valencia':df_val_test,'allcenters':df_all_test}\n",
    "# iterate on trained models and datasets\n",
    "df_tralability = pd.DataFrame()\n",
    "for modelname in model_dict.keys():\n",
    "    model = model_dict[modelname]\n",
    "    for dataname in dataset_dict.keys():\n",
    "        data = dataset_dict[dataname]\n",
    "        \n",
    "        df_processed = model.process_data(data,train=False)\n",
    "        predictions = model.predict(df_processed)\n",
    "        df_processed['segmental_score'] = predictions\n",
    "\n",
    "\n",
    "        df_sel = df_processed[(df_processed.FLAG_QC==False)&(df_processed['class'].isin(['segm','eup']))]\n",
    "        y_test = df_sel['class']=='segm'\n",
    "        y_pred_score = df_sel['segmental_score']\n",
    "        logit_roc_auc = roc_auc_score(y_test, y_pred_score)\n",
    "        df_tralability = df_tralability.append({'model':modelname,'data':dataname,'auroc':logit_roc_auc}, ignore_index=True)\n",
    "\n",
    "# y_test riporta la classificazione in vero o falso\n",
    "# y_pred_score sono le probabilità assegnate per fare la classificazione \n",
    "# entrmabi sono due vettori della lunghezza uguale\n",
    "# logit_roc_auc, punteggio dell'area sotto la curva\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tralability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tralability_pivot = df_tralability.pivot(index='model',columns='data')\n",
    "df_tralability_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette= sns.color_palette(\"vlag\", as_cmap=True)\n",
    "sns.heatmap(data = df_tralability_pivot, cmap = palette, annot = True)\n",
    "plt.title('AUROC contingency table')\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(output_dir,'model_traslability.jpeg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curves\n",
    "##### ROC segmentals and euploids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {'GeneraLife':df_roma,'Care-Fertility':df_uk,'IVIRMA':df_valencia,'allcenters':df_all}\n",
    "\n",
    "\n",
    "for center in dataset_dict.keys():\n",
    "    dataset = dataset_dict[center]\n",
    "    \n",
    "    dataset_train0, dataset_test0 = train_test_split(dataset[dataset['class'].isin(['segm','eup'])], test_size=0.4,random_state=104)\n",
    "    dataset_train = dataset_train0.copy()\n",
    "    dataset_test = dataset_test0.copy()\n",
    "    tl = TimeLapseAnalyzer()\n",
    "    tl.train(dataset_train,\n",
    "             model_feature_list = selected_feature_list+['pca_ll'],target='is_segmental')\n",
    "    dataset_test_processed = tl.process_data(dataset_test,train=False)\n",
    "    dataset_test_processed['segmental_score'] = tl.predict(dataset_test_processed)\n",
    "\n",
    "    dataset_train_processed = tl.process_data(dataset_train,train=False)\n",
    "    dataset_train_processed['segmental_score'] = tl.predict(dataset_train_processed)\n",
    "    \n",
    "    # eukutation on train set\n",
    "\n",
    "    df_sel = dataset_train_processed[(dataset_train_processed.FLAG_QC==False)]\n",
    "    y_test = df_sel['class']=='segm'\n",
    "    y_pred_score = df_sel['segmental_score']\n",
    "    logit_roc_auc_train = roc_auc_score(y_test,y_pred_score)\n",
    "    fpr_train, tpr_train, thresholds = roc_curve(y_test, y_pred_score)\n",
    "\n",
    "    df_sel = dataset_test_processed[(dataset_test_processed.FLAG_QC==False)]\n",
    "    y_test = df_sel['class']=='segm'\n",
    "    y_pred_score = df_sel['segmental_score']\n",
    "    logit_roc_auc = roc_auc_score(y_test,y_pred_score)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_score)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr_train, tpr_train, label='Train Data (area = %0.3f)' % logit_roc_auc_train)\n",
    "    plt.plot(fpr, tpr, label='Test Data (area = %0.3f)' % logit_roc_auc)\n",
    "\n",
    "    #plt.plot(fpr_ida, tpr_ida, label='IDA Score (area = %0.3f)' % logit_roc_auc_ida)\n",
    "    #plt.plot(fpr_grading, tpr_grading, label='Grading Score (area = %0.3f)' % logit_roc_auc_grading)\n",
    "\n",
    "    plt.plot([-0.05, 1.05], [-0.05, 1.05],'r--')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title(center)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    #plt.savefig(os.path.join(output_dir,'roc_segm_vs_eup_'+center+'.jpeg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC euploids vs aneuploid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {'GeneraLife':df_roma,'Care-Fertility':df_uk,'IVIRMA':df_valencia,'Multicenter':df_all}\n",
    "\n",
    "\n",
    "for center in dataset_dict.keys():\n",
    "    dataset = dataset_dict[center]\n",
    "    \n",
    "    dataset_train0, dataset_test0 = train_test_split(dataset[dataset['class'].isin(['aneup','eup'])], test_size=0.4,random_state=104)\n",
    "    dataset_train = dataset_train0.copy()\n",
    "    dataset_test = dataset_test0.copy()\n",
    "    tl = TimeLapseAnalyzer()\n",
    "    tl.train(dataset_train,\n",
    "             model_feature_list = selected_feature_list+['pca_ll'],target='is_aneuploid')\n",
    "    dataset_test_processed = tl.process_data(dataset_test,train=False)\n",
    "    dataset_test_processed['aneup_score'] = tl.predict(dataset_test_processed)\n",
    "\n",
    "    dataset_train_processed = tl.process_data(dataset_train,train=False)\n",
    "    dataset_train_processed['aneup_score'] = tl.predict(dataset_train_processed)\n",
    "    \n",
    "\n",
    "    df_sel = dataset_train_processed[(dataset_train_processed.FLAG_QC==False)]\n",
    "    y_test = df_sel['class']=='aneup'\n",
    "    y_pred_score = df_sel['aneup_score']\n",
    "    logit_roc_auc_train = roc_auc_score(y_test,y_pred_score)\n",
    "    fpr_train, tpr_train, thresholds = roc_curve(y_test, y_pred_score)\n",
    "\n",
    "    df_sel = dataset_test_processed[(dataset_test_processed.FLAG_QC==False)]\n",
    "    y_test = df_sel['class']=='aneup'\n",
    "    y_pred_score = df_sel['aneup_score']\n",
    "    logit_roc_auc = roc_auc_score(y_test,y_pred_score)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_score)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr_train, tpr_train, label='Train Data (area = %0.3f)' % logit_roc_auc_train)\n",
    "    plt.plot(fpr, tpr, label='Test Data (area = %0.3f)' % logit_roc_auc)\n",
    "    plt.plot([-0.05, 1.05], [-0.05, 1.05],'r--')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title(center)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    #plt.savefig(os.path.join(output_dir,'roc_aneup_vs_eup_'+center+'.jpeg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC segmentals and euploids+aneuploids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {'GeneraLife':df_roma,'Care-Fertility':df_uk,'IVIRMA':df_valencia,'Multicenter':df_all}\n",
    "\n",
    "\n",
    "for center in dataset_dict.keys():\n",
    "    dataset = dataset_dict[center]\n",
    "    \n",
    "    dataset_train0, dataset_test0 = train_test_split(dataset[dataset['class'].isin(['segm','aneup','eup'])], test_size=0.4,random_state=104)\n",
    "    dataset_train = dataset_train0.copy()\n",
    "    dataset_test = dataset_test0.copy()\n",
    "    tl = TimeLapseAnalyzer()\n",
    "    tl.train(dataset_train,\n",
    "             model_feature_list = selected_feature_list+['pca_ll'],target='is_segmental')\n",
    "    dataset_test_processed = tl.process_data(dataset_test,train=False)\n",
    "    dataset_test_processed['segmental_score'] = tl.predict(dataset_test_processed)\n",
    "\n",
    "    dataset_train_processed = tl.process_data(dataset_train,train=False)\n",
    "    dataset_train_processed['segmental_score'] = tl.predict(dataset_train_processed)\n",
    "    \n",
    "    # eukutation on train set\n",
    "\n",
    "    df_sel = dataset_train_processed[(dataset_train_processed.FLAG_QC==False)]\n",
    "    y_test = df_sel['class']=='segm'\n",
    "    y_pred_score = df_sel['segmental_score']\n",
    "    logit_roc_auc_train = roc_auc_score(y_test,y_pred_score)\n",
    "    fpr_train, tpr_train, thresholds = roc_curve(y_test, y_pred_score)\n",
    "\n",
    "    df_sel = dataset_test_processed[(dataset_test_processed.FLAG_QC==False)]\n",
    "    y_test = df_sel['class']=='segm'\n",
    "    y_pred_score = df_sel['segmental_score']\n",
    "    logit_roc_auc = roc_auc_score(y_test,y_pred_score)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_score)\n",
    "    \n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr_train, tpr_train, label='Train Data (area = %0.3f)' % logit_roc_auc_train)\n",
    "    plt.plot(fpr, tpr, label='Test Data (area = %0.3f)' % logit_roc_auc)\n",
    "    plt.plot([-0.05, 1.05], [-0.05, 1.05],'r--')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title(center)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    #plt.savefig(os.path.join(output_dir,'roc_segm_vs_aneup_or_eup_'+center+'.jpeg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC for centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 split datasets\n",
    "df_all['is_GeneraLife'] = df_all['centre_ID'] == 'GeneraLife'\n",
    "df_all['is_IVIRMA'] = df_all['centre_ID'] == 'IVIRMA'\n",
    "df_all['is_Care-Fertility'] = df_all['centre_ID'] == 'Care-Fertility'\n",
    "\n",
    "\n",
    "for center1,center2 in [('GeneraLife','IVIRMA'),('GeneraLife','Care-Fertility'),('IVIRMA','Care-Fertility')]:\n",
    "    target = 'is_'+ center1\n",
    "\n",
    "    df_center_train0, df_center_test0 = train_test_split(df_all[(df_all['class']=='segm')\n",
    "                                                                &(df_all['centre_ID'].isin([center1,center2]))], \n",
    "                                                         test_size=0.4,random_state=104)\n",
    "    df_center_train = df_center_train0.copy()\n",
    "    df_center_test = df_center_test0.copy()\n",
    "\n",
    "\n",
    "    #1 train 4 models: model specific and global model\n",
    "    tl_center = TimeLapseAnalyzer()\n",
    "    tl_center.train(df_center_train,model_feature_list = tl_center.imputed_times+['pca_ll'],target=target)\n",
    "    df_center_train_processed = tl_center.process_data(df_center_train,train=False)\n",
    "    df_center_test_processed = tl_center.process_data(df_center_test,train=False)\n",
    "    df_center_train_processed['center_score'] = tl_center.predict(df_center_train_processed)\n",
    "    df_center_test_processed['center_score'] = tl_center.predict(df_center_test_processed)\n",
    "    \n",
    "    # evalutation on test set\n",
    "    plt.figure()\n",
    "    y_pred_score = df_center_test_processed['center_score']\n",
    "    y_test = df_center_test_processed[target]\n",
    "    logit_roc_auc = roc_auc_score(y_test,y_pred_score)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_score)\n",
    "\n",
    "    y_pred_score = df_center_train_processed['center_score']\n",
    "    y_test = df_center_train_processed[target]\n",
    "    logit_roc_auc_train = roc_auc_score(y_test,y_pred_score)\n",
    "    fpr_train, tpr_train, thresholds = roc_curve(y_test, y_pred_score)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title(center1+' vs '+center2)\n",
    "    plt.plot(fpr, tpr, label='Test Data (area = %0.3f)' % logit_roc_auc)\n",
    "    plt.plot(fpr_train, tpr_train, label='Train Data (area = %0.3f)' % logit_roc_auc_train)\n",
    "\n",
    "\n",
    "    plt.plot([-0.05, 1.05], [-0.05, 1.05],'r--')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    #plt.title('Curve ROC per centro')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    #plt.savefig(os.path.join(output_dir,'roc_'+center1+'_vs_'+center2+'.jpeg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_all = tl_all.process_data(df_all, train=False)\n",
    "predictions = tl_all.predict(df_processed_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_processed_all[['FLAG_QC','FLAG_QC_NUM_MISSING',\n",
    "    'FLAG_QC_NOT_MONOTONY','FLAG_QC_MISSING_BLASTO','FLAG_QC_PCA']].mean())\n",
    "\n",
    "display(df_processed_all.groupby('centre_ID')[['FLAG_QC','FLAG_QC_NUM_MISSING',\n",
    " 'FLAG_QC_MISSING_BLASTO', 'FLAG_QC_NOT_MONOTONY','FLAG_QC_PCA']].mean())\n",
    "\n",
    "display(df_processed_all.groupby('class')[['FLAG_QC','FLAG_QC_NUM_MISSING',\n",
    " 'FLAG_QC_MISSING_BLASTO', 'FLAG_QC_NOT_MONOTONY','FLAG_QC_PCA']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"rocket\", as_cmap=True)\n",
    "sns.scatterplot(data=df_processed_all, x='pca1', y='pca2', hue='pca_ll',s=50,palette=palette,alpha=0.7)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('papap')\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(output_dir,'pca_outlers_all_ll.jpeg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_processed_all,x='pca1',y='pca2',hue='FLAG_QC_PCA',s=50,alpha=0.7)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('ajaja')\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(output_dir,'pca_outlers_all_QC.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_processed_all[df_processed_all.centre_ID.isin(['IVIRMA','GeneraLife','Care-Fertility'])],x='pca1',y='pca2',hue='centre_ID',s=50,alpha=0.4,hue_order=['IVIRMA','GeneraLife','Care-Fertility'])\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('sosos')\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(output_dir,'pca_outlers_all_centers.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"rocket\", as_cmap=True)\n",
    "ax = sns.jointplot(x=df_processed_all['pca1'],y=df_processed_all['pca2'],\n",
    "                   kind='scatter',\n",
    "                   space=0,\n",
    "                   alpha=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_outliers = df_processed_all.sort_values('pca_ll').index[0:8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_all.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for embryo_idx in list_outliers:\n",
    "    outfile = os.path.join(output_dir, 'embryo' + str(embryo_idx) + '.jpeg')\n",
    "    plot_imputation(df_processed_all,\n",
    "                    embryo_idx,\n",
    "                    outputfile = outfile,\n",
    "                    time_list=['t0'] + tl_roma.list_time_features,\n",
    "                    ymax=240)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list_imputed = df_processed_all[df_processed_all.num_missing==5].sort_values('pca_ll',ascending=False).index[0:7].values\n",
    "\n",
    "#esempio outlier\n",
    "for embryo_idx in list_imputed:\n",
    "    outfile = os.path.join(output_dir,'embryo'+str(embryo_idx)+'.jpeg')\n",
    "    plot_imputation(df_processed_all,\n",
    "                    embryo_idx,\n",
    "                    outputfile = outfile,\n",
    "                    time_list=['t0'] + tl_roma.list_time_features,\n",
    "                    ymax=240)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list_outliers_minor = df_processed_all[df_processed_all.FLAG_QC_PCA==True].sort_values('pca_ll',ascending=False).index[0:8].values\n",
    "\n",
    "#esempio outlier\n",
    "for embryo_idx in list_outliers_minor:\n",
    "    outfile = os.path.join(output_dir,'embryo'+str(embryo_idx)+'.jpeg')\n",
    "    plot_imputation(df_processed_all,embryo_idx,outputfile=outfile,time_list=['t0']+tl_roma.list_time_features,ymax=240)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list_imputed = df_processed_all[df_processed_all.num_missing==5].sort_values('pca_ll',ascending=False).index[0:7].values\n",
    "\n",
    "#esempio outlier\n",
    "for embryo_idx in list_imputed:\n",
    "    outfile = os.path.join(output_dir,'embryo'+str(embryo_idx)+'.jpeg')\n",
    "    plot_imputation(df_processed_all,embryo_idx,outputfile=outfile,time_list=['t0']+tl_roma.list_time_features,ymax=240)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delays trajectories\n",
    "1. Full dataset\n",
    "2. IVIRMA\n",
    "3. Care-Fertility\n",
    "4. GeneraLife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trajectories full dataset\n",
    "dataset = df_all_processed[df_all_processed.FLAG_QC==False]\n",
    "plotting_times = ['tPNa_imp', 'tPNf_imp', 't2_imp', 't3_imp', 't4_imp',\n",
    "       't5_imp', 't6_imp', 't7_imp', 't8_imp', 't9_imp', 'tM_imp',\n",
    "       'tSB_imp', 'tB_imp', 'tEB_imp']\n",
    "plt.title('Delays trajectories in full and segmental aneuploidies - All centers')\n",
    "plot_trajectory_new(dataset,plotting_times,outfile=os.path.join(output_dir,'trajectories_all.jpeg'))\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "plt.ylim(0, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trajectories val\n",
    "dataset = df_valencia_processed[df_valencia_processed.FLAG_QC==False]\n",
    "plotting_times = ['tPNa_imp', 'tPNf_imp', 't2_imp', 't3_imp', 't4_imp',\n",
    "       't5_imp', 't6_imp', 't7_imp', 't8_imp', 't9_imp', 'tM_imp',\n",
    "       'tSB_imp', 'tB_imp', 'tEB_imp']\n",
    "plot_trajectory_new(dataset,plotting_times,outfile=os.path.join(output_dir,'trajectories_valencia.jpeg'))\n",
    "plt.title('Delays trajectories in full and segmental aneuploidies - IVIRMA')\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "plt.ylim(0, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_roma_processed[df_roma_processed.FLAG_QC==False]\n",
    "plotting_times = ['tPNa_imp', 'tPNf_imp', 't2_imp', 't3_imp', 't4_imp',\n",
    "       't5_imp', 't6_imp', 't7_imp', 't8_imp', 't9_imp', 'tM_imp',\n",
    "       'tSB_imp', 'tB_imp', 'tEB_imp']\n",
    "plot_trajectory_new(dataset,plotting_times,outfile=os.path.join(output_dir,'trajectories_roma.jpeg'))\n",
    "plt.title('Delays trajectories in full and segmental aneuploidies - GeneraLife')\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "plt.ylim(0, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trajectories uk\n",
    "dataset = df_uk_processed[df_uk_processed.FLAG_QC==False]\n",
    "plotting_times = ['tPNa_imp', 'tPNf_imp', 't2_imp', 't3_imp', 't4_imp',\n",
    "       't5_imp', 't6_imp', 't7_imp', 't8_imp', 't9_imp', 'tM_imp',\n",
    "       'tSB_imp', 'tB_imp', 'tEB_imp']\n",
    "plot_trajectory_new(dataset,plotting_times,outfile=os.path.join(output_dir,'trajectories_uk.jpeg'))\n",
    "plt.title('Delays trajectories in full and segmental aneuploidies - Care-Fertility')\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "plt.ylim(0, 4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63809d3f4ca1651812e840d21e7c64c312375b15a820b284ca77cdf42cc291b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
